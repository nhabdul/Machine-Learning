{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963514d9-2683-4e9e-96d7-a26cc3865f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: linear\n",
      "Accuracy: 0.7763157894736842\n",
      "Confusion Matrix:\n",
      " [[32  1  9]\n",
      " [ 2 51  6]\n",
      " [ 7  9 35]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.78      0.76      0.77        42\n",
      "         Low       0.84      0.86      0.85        59\n",
      "      Medium       0.70      0.69      0.69        51\n",
      "\n",
      "    accuracy                           0.78       152\n",
      "   macro avg       0.77      0.77      0.77       152\n",
      "weighted avg       0.78      0.78      0.78       152\n",
      "\n",
      "\n",
      "Kernel: rbf\n",
      "Accuracy: 0.7828947368421053\n",
      "Confusion Matrix:\n",
      " [[32  1  9]\n",
      " [ 0 48 11]\n",
      " [ 7  5 39]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.82      0.76      0.79        42\n",
      "         Low       0.89      0.81      0.85        59\n",
      "      Medium       0.66      0.76      0.71        51\n",
      "\n",
      "    accuracy                           0.78       152\n",
      "   macro avg       0.79      0.78      0.78       152\n",
      "weighted avg       0.79      0.78      0.79       152\n",
      "\n",
      "\n",
      "Kernel: poly\n",
      "Accuracy: 0.6907894736842105\n",
      "Confusion Matrix:\n",
      " [[22  1 19]\n",
      " [ 0 38 21]\n",
      " [ 3  3 45]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.88      0.52      0.66        42\n",
      "         Low       0.90      0.64      0.75        59\n",
      "      Medium       0.53      0.88      0.66        51\n",
      "\n",
      "    accuracy                           0.69       152\n",
      "   macro avg       0.77      0.68      0.69       152\n",
      "weighted avg       0.77      0.69      0.70       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(\"medv\", axis=1)\n",
    "y = data[\"medv\"]\n",
    "\n",
    "# Step 1: Binning the target variable into classes (e.g., Low, Medium, High price)\n",
    "y_binned = pd.qcut(y, q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models with different kernels\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Step 2: Train SVC with the given kernel\n",
    "    model = SVC(kernel=kernel)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 3: Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Step 4: Calculate accuracy, confusion matrix, and classification report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store results for each kernel\n",
    "    results[kernel] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Print results for each kernel\n",
    "for kernel, metrics in results.items():\n",
    "    print(f\"\\nKernel: {kernel}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])\n",
    "    print(\"Classification Report:\\n\", metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1982d10-5884-4190-97d5-4b180bf6e583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: linear\n",
      "Accuracy: 0.8212765957446808\n",
      "Confusion Matrix:\n",
      " [[103  35]\n",
      " [  7  90]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83       138\n",
      "           1       0.72      0.93      0.81        97\n",
      "\n",
      "    accuracy                           0.82       235\n",
      "   macro avg       0.83      0.84      0.82       235\n",
      "weighted avg       0.85      0.82      0.82       235\n",
      "\n",
      "\n",
      "Kernel: rbf\n",
      "Accuracy: 0.8170212765957446\n",
      "Confusion Matrix:\n",
      " [[112  26]\n",
      " [ 17  80]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       138\n",
      "           1       0.75      0.82      0.79        97\n",
      "\n",
      "    accuracy                           0.82       235\n",
      "   macro avg       0.81      0.82      0.81       235\n",
      "weighted avg       0.82      0.82      0.82       235\n",
      "\n",
      "\n",
      "Kernel: poly\n",
      "Accuracy: 0.7829787234042553\n",
      "Confusion Matrix:\n",
      " [[118  20]\n",
      " [ 31  66]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       138\n",
      "           1       0.77      0.68      0.72        97\n",
      "\n",
      "    accuracy                           0.78       235\n",
      "   macro avg       0.78      0.77      0.77       235\n",
      "weighted avg       0.78      0.78      0.78       235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the earthquake dataset\n",
    "file_path = ('file:///Users/hudaabdul/Library/CloudStorage/OneDrive-Personal/MSc in Data Science/Machine Learning/Datasets/earthquake_data.csv') \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define features and target\n",
    "X = data[['cdi', 'mmi', 'sig', 'nst', 'dmin', 'gap', 'depth', 'latitude', 'longitude']]\n",
    "y = data['tsunami']  # Using 'tsunami' as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models with different kernels\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "results = {}\n",
    "\n",
    "# Train SVC models with each kernel and store results\n",
    "for kernel in kernels:\n",
    "    model = SVC(kernel=kernel)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy, confusion matrix, and classification report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store results for each kernel\n",
    "    results[kernel] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Print results for each kernel\n",
    "for kernel, metrics in results.items():\n",
    "    print(f\"\\nKernel: {kernel}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])\n",
    "    print(\"Classification Report:\\n\", metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b60916-98c2-41f1-a12d-407d342b2cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
